{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e54e8911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.agents import create_agent\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langchain.chat_models import init_chat_model\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da2d0d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class User:\n",
    "    username: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0cadfafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\"openai:gpt-4o\")\n",
    "token = os.getenv(\"GITHUB_PERSONAL_ACCESS_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "385b0aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCP Client created successfully\n"
     ]
    }
   ],
   "source": [
    "client = MultiServerMCPClient(\n",
    "        {\n",
    "            \"github\": {\n",
    "                \"command\": \"npx\",\n",
    "                \"args\": [\"-y\", \"@modelcontextprotocol/server-github\"],\n",
    "                \"env\": {\"GITHUB_PERSONAL_ACCESS_TOKEN\": token},\n",
    "                \"transport\": \"stdio\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "print(\"MCP Client created successfully\")\n",
    "tools = await client.get_tools()\n",
    "# print(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ce5e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dynamic_prompt\n",
    "def user_context_prompt(request: ModelRequest) -> str:\n",
    "    \"\"\"Dynamic system prompt using runtime context.\"\"\"\n",
    "    username = \"unknown\"\n",
    "    if hasattr(request.runtime.context, 'username'):\n",
    "        username = request.runtime.context.username\n",
    "\n",
    "    system_prompt = f\"\"\"You have access to GitHub tools. When the user asks about GitHub data \n",
    "(commits, repos, issues, etc.), ALWAYS use the available GitHub tools to fetch real data.\n",
    "Never say you can't access this information - use the tools provided.\n",
    "\n",
    "IMPORTANT: The authenticated GitHub user is `{username}`. When the user says \"my commits\", \n",
    "\"your commits\", or asks about \"you\" in a GitHub context, they mean the GitHub user `{username}`, \n",
    "NOT you (the AI assistant). Always query GitHub for user `{username}` when asked about \n",
    "personal GitHub activity.\"\"\"\n",
    "\n",
    "    return system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3dbf378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    llm,\n",
    "    tools,\n",
    "    context_schema=User,\n",
    "    middleware=[user_context_prompt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b6b0816c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call attempted: [{'name': 'search_repositories', 'args': {'query': 'user:aayushmaanhooda'}, 'id': 'call_O1vX8TkxcvWj8JIot21iZp6L', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "res = await agent.ainvoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"use github tool and tell me how many github commits you have done in 2026?\"}]},\n",
    "    context=User(username=\"aayushmaanhooda\")\n",
    ")\n",
    "\n",
    "try:\n",
    "    res = await agent.ainvoke(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": \"List all repositories for user aayushmaanhooda on GitHub\"}]},\n",
    "        context=User(username=\"aayushmaanhooda\")\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    \n",
    "# Check intermediate messages before the error\n",
    "for msg in res.get(\"messages\", []):\n",
    "    if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "        print(\"Tool call attempted:\", msg.tool_calls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e52b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3a5537",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
